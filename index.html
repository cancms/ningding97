<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ning Ding</title>
<meta name="description" content="">

<!-- Open Graph -->

<meta property="og:site_name" content="" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="https://github.com/ningding97//" />
<meta property="og:description" content="Ning Ding" />
<meta property="og:image" content="true" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://raw.githubusercontent.com/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üìü</text></svg>">

<link rel="stylesheet" href="/ningding97/assets/css/main.css">

<link rel="canonical" href="/ningding97/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->





<!-- Panelbear Analytics - We respect your privacy -->
<script async src="https://cdn.panelbear.com/analytics.js?site=93OoYW0z85N"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: '93OoYW0z85N' });
</script>

    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="/ningding97/assets/js/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://github.com/ningding97//">
        
    <div class="social">
      <div class="contact-icons">
      <a href="mailto:%6E%69%6E%67%64%69%6E%67.%63%73@%67%6D%61%69%6C.%63%6F%6D" class="icon-with-tooltip email-icon" title="email">
    <span style="position: relative;">
       <i class="fa-solid fa-envelope"></i>
        <span class="tooltip-bubble">Email</span>
    </span>
</a>
<a href="https://scholar.google.com/citations?user=uZXQuYAAAAAJ&hl=zh-CN" class="icon-with-tooltip scholar-icon" title="Google Scholar">
    <span style="position: relative;">
        <i class="fa-brands fa-google"></i>
        <span class="tooltip-bubble">Google Scholar</span>
    </span>
</a>
<a href="https://www.semanticscholar.org/author/46649145" class="icon-with-tooltip semanticscholar-icon" title="Semantic Scholar">
    <span style="position: relative;">
        <i class="ai ai-semantic-scholar" style="font-size: 1.2em; vertical-align: -2px;"></i>
        <span class="tooltip-bubble">Semantic Scholar</span>
    </span>
</a>
<a href="https://github.com/ningding97" class="icon-with-tooltip github-icon" title="GitHub">
    <span style="position: relative;">
        <!-- <svg xmlns="http://www.w3.org/2000/svg" style="margin-bottom: 5px" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-activity"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg> -->
        <i class="fa-brands fa-github"></i>
        <span class="tooltip-bubble">GitHub</span>
    </span>
</a>
<a href="https://twitter.com/stingning" class="icon-with-tooltip twitter-icon" title="Twitter">
    <span style="position: relative;">
        <i class="fa-brands fa-square-x-twitter"></i>
        <span class="tooltip-bubble">X</span>
    </span>
</a>


<style>
.icon-with-tooltip span.tooltip-bubble {
    visibility: hidden;
    min-width: 110px;
    max-width: 230px;
    background: #fff;
    color: #343c4d;
    text-align: center;
    border-radius: 12px;
    padding: 6px 14px;
    position: absolute;
    z-index: 11;
    bottom: -37px;
    left: 50%;
    transform: translateX(-50%) translateY(10px) scale(0.98);
    opacity: 0;
    box-shadow: 0 6px 24px 0 rgba(40,60,116,0.13), 0 1.5px 6px 0 rgba(0,0,0,0.08); /* ÊüîÂíåÁöÑÂèåÂ±ÇÈò¥ÂΩ± */
    font-size: 14px;
    white-space: nowrap;
    transition:
        opacity 0.35s cubic-bezier(.41,.6,.67,1.01),
        transform 0.32s cubic-bezier(.41,.6,.67,1.01),
        box-shadow 0.3s;
    pointer-events: none;
}

.icon-with-tooltip span.tooltip-bubble::after {
    content: "";
    position: absolute;
    top: -10px;
    left: 50%;
    transform: translateX(-50%);
    border-width: 5px;
    border-style: solid;
    border-color: transparent transparent #fff transparent;
    filter: drop-shadow(0 3px 8px rgba(40,60,116,0.12));
}

.icon-with-tooltip:hover span.tooltip-bubble,
.icon-with-tooltip:focus-within span.tooltip-bubble {
    visibility: visible;
    opacity: 1;
    transform: translateX(-50%) translateY(0) scale(1.03);
    box-shadow: 0 12px 32px 0 rgba(40,60,116,0.18), 0 2px 8px 0 rgba(0,0,0,0.09);
    transition:
        opacity 0.33s cubic-bezier(.31,.86,.44,1.02),
        transform 0.37s cubic-bezier(.31,.86,.44,1.02),
        box-shadow 0.3s;
}
</style>
      </div>
      <div class="contact-note"></div>
      </div>
      

       <!-- Ning Ding -->
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap" style="margin-left: 330px;">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/ningding97/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/ningding97/publications/">
                papers
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/ningding97/projects/">
                projects
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/weather-icons/2.0.9/css/weather-icons.min.css">
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.7.1/dist/leaflet.css" />
  <script type="text/javascript" src="https://stamen-maps.a.ssl.fastly.net/js/tile.stamen.js?v1.3.0"></script>
  <script src="https://unpkg.com/leaflet@1.7.1/dist/leaflet.js"></script>
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.7.1/dist/leaflet.css" integrity="sha512-xodZBNTC5n17Xt2atTPuE1HxjVMSvLVW9ocqUKLsCC5CXdbqCmblAshOMAS6/keqq/sMZMZ19scR4PsZChSR7A==" crossorigin=""/>
  <script src="https://unpkg.com/leaflet@1.7.1/dist/leaflet.js" integrity="sha512-XQoYMqMTK8LvdxXYG3nZ448hOEQiglfqkJs1NOQV44cWnUrBc8PkAOcXy20w0vlaXaVUearIOBhiXZ5V3ynxwA==" crossorigin=""></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/weather-icons/2.0.9/css/weather-icons.min.css" /> -->




<!-- Panelbear Analytics - We respect your privacy -->
<script async src="https://cdn.panelbear.com/analytics.js?site=93OoYW0z85N"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: '93OoYW0z85N' });
</script>



<div class="post">

  <header class="post-header">
    <h3 class="post-title">
     <span class="font-weight-thin">Ning</span>  Ding &nbsp; <span style="font-family: 'PingFang SC', serif; color: #504c4c;">‰∏ÅÂÆÅ</span> 
    </h3>
    <!-- <div class="job-info" style="margin-top: 10px; text-align: left;>
      <p style="color: #402F7C; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px;">
        Assistant Professor @ Tsinghua University<br>
      </p>
    </div> -->
    <div>
      <span id="date" style="color: rgb(53, 52, 52); font-family:'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif"></span>.
    </div>



    <script>
      const dateElement = document.getElementById('date');
      const today = new Date();
      const options = { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' };
      dateElement.textContent = today.toLocaleDateString('en-US', options);
    </script>
    
    <div>
      <span style="color: rgb(57, 56, 56); font-family:'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif">  </span>
      <span id="weather-text" style="color: rgb(65, 64, 64); font-family:'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif"></span>
      <html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Beijing Weather Icon</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/weather-icons/2.0.9/css/weather-icons.min.css">
  <style>
    #weather-icon i {
      color: grey;
    }
  </style>
</head>
<body>
  <div id="weather-icon"></div>
    
    </div>


    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script>
      $(document).ready(function () {
        const apiKey = '916a98b48a576641bb870cfd458d045f';
        const city = 'Beijing';
        const url = `https://api.openweathermap.org/data/2.5/weather?q=${city}&appid=${apiKey}&units=metric`;

        fetch(url)
          .then((response) => response.json())
          .then((data) => {
            const weatherCode = data.weather[0].id;
            const iconClass = `wi wi-owm-${weatherCode}`;
            $('#weather-icon').addClass(iconClass);
          })
          .catch((error) => console.error('Error fetching weather data:', error));
      });
    </script>

    
    <script>
      const textElement = document.getElementById('weather-text');
      const apiKey = '916a98b48a576641bb870cfd458d045f';
      const city = 'Beijing';
      const url = `https://api.openweathermap.org/data/2.5/weather?q=${city}&appid=${apiKey}&units=metric`;

      fetch(url)
        .then(response => response.json())
        .then(data => {
          const temperature = (data.main.temp).toFixed(1);
          const fahrenheit = ((temperature * 9/5) + 32).toFixed(1);
          const description = data.weather[0].description;
          textElement.textContent = `@${city} ${temperature}¬∞C / ${fahrenheit}¬∞F, ${description}.`;
        })
        .catch(error => {
          console.error('Error fetching weather data:', error);
          textElement.textContent = 'Unable to fetch weather data.';
        });
    </script>
    
   </small>

  </header>
  <br>
  <article style="max-width: 780px">
    
    <div class="profile float-right" >
      
        <img class="img-fluid rounded profile-image" src="/ningding97/assets/img/avatar.jpeg" style="width:100%; max-width: 375px; margin-top: 30px; border: none; margin-left: -47px;">
      
      <div class="profile-name" style="margin-top: 10px; text-align: left; margin-left: -40px;">
        <p style="color: #402F7C; font-size: 15px;">Assistant Professor @ Tsinghua </p>
      <!-- <div class="email-container" style="margin-top: 10px; text-align: left; margin-left: -47px;">
        <a href="mailto:ningding.cs@gmail.com" style="text-decoration: none; color: #402F7C; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; transition: color 0.3s ease;">
          <i class="fas fa-envelope" style="margin-right: 5px;"></i>
          ningding.cs AT gmail DOT com
        </a>
      </div> -->
    </div>
      


    </div>
    <div class="profile-text">
      <div class="clearfix" style="width: 100%; max-width: 800px; padding-left: 52px;">
        <h4 id="bio">Bio</h4>

<p>I am a tenure-track Assistant Professor at the <a href="https://www.ee.tsinghua.edu.cn/">Department of Electronic Engineering</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>.
Previously, I was a postdoc researcher in the same department, advised by Prof. Bowen Zhou.
I received Ph.D. at the Department of Computer Science and Technology,  Tsinghua Univeristy in 2023, advised by Prof. Hai-Tao Zheng and also co-advised by Prof. Zhiyuan Liu.</p>

<h4 id="research">Research</h4>
<p>My research spans the areas of natural language processing and machine learning. 
Currently I am working on theories and <em>scalable</em> methods for developing reasoning intelligence that balances exploration and learning. I am also interested in how specialized general reasoners can facilitate scientific innovations.</p>


      </div>
    </div>

    



  </article>



  <div class="recruitment-infobox" style="width: 88%; background: transparent; margin-top: 15px; margin-bottom: 0px;">
    <div class="infobox-header" onclick="toggleInfobox()">
      <i class="fas fa-plus-circle toggle-icon"></i>
      <h6 style="margin: 0; color: #3E3E3E; font-size: 15px; font-weight: 400; display: flex; align-items: center; width: 100%;">
        <span>Lab Information</span>
        <span class="lab-header-links" style="display: flex; margin-left: 150px;">
          <a href="https://c3i.ee.tsinghua.edu.cn/en/" target="_blank" class="lab-link" style="font-weight: 400; margin-right:30px;">
            <i class="fas fas fa-project-diagram" style="font-size: 1em;"></i> Group Homepage
          </a>
          <a href="https://github.com/PRIME-RL" target="_blank" class="lab-link" style="font-weight: 400; margin-right:7px;">
            <i class="fab fa-github"></i> PRIME-RL,
          </a>
          <a href="https://github.com/TsinghuaC3I" target="_blank" class="lab-link" style="font-weight: 400;margin-right:40px;">
            THU-C3I
          </a>
        </span>
      </h6>
    </div>
    <div class="infobox-content" style="display: none;">
      <p>Our group is looking for self-motivated Ph.D. students, Postdocs, and interns. Research topics include but are not limited to scalable reinforcement learning, fundamental theories, scientific applications of reasoning language models.  </p>
      <p>
      If you are interested, please drop me an email to <b>ningding.cs@gmail.com</b> or <b>dingning@mail.tsinghua.edu.cn</b> with your CV and research interests.</p>
    </div>
  </div>
  
  <style>
    .lab-links {
  margin-top: 6px;
  display: flex;
  gap: 20px;
}
.lab-link {
  display: flex;
  align-items: center;
  font-size: 15px;
  color: #365485;
  text-decoration: none;
  transition: color 0.18s;
  font-weight: 500;
}
.lab-link:hover {
  color: #1768ac;
  text-decoration: underline;
}
.lab-link i {
  font-size: 1.13em;
  margin-right: 7px;
  color: #5172a1;
  vertical-align: middle;
  transition: color 0.15s;
}
.lab-link:hover i {
  color: #1768ac;
}
    .recruitment-infobox {
      margin: 25px 0;
      border-radius: 12px;
      background-color: rgba(240, 245, 250, 0.5);
      overflow: hidden;
      width: 100%; /* ‰ΩøÁî®Êï¥‰∏™ÂÆΩÂ∫¶ */
      max-width: none; /* ÂèñÊ∂àÊúÄÂ§ßÂÆΩÂ∫¶ÈôêÂà∂ */
      transition: all 0.3s ease;
    }
    .recruitment-infobox:hover {
      box-shadow: 0 6px 18px rgba(0,0,0,0.08);
      transform: translateY(-2px);
    }
    .infobox-header {
      padding: 14px 18px;
      background: linear-gradient(to right, rgba(240, 244, 249, 0.8), rgba(245, 249, 252, 0.8)); /* Increased transparency */
      font-size: 16px;
      font-weight: 500;
      color: #3a4a64;
      cursor: pointer;
      display: flex;
      align-items: center;
      transition: all 0.2s;
    }
    .infobox-header:hover {
      background: linear-gradient(to right, #e8f2fa, #edf5fc);
    }
    .toggle-icon {
      margin-right: 12px;
      color: #4a6fa5;
      transition: transform 0.3s ease, color 0.2s;
    }
    .toggle-icon.open {
      transform: rotate(45deg);
      color: #3a5a8c;
    }
    .infobox-content {
      padding: 18px;
      line-height: 1.6;
      color: #445566;
      background-color: rgba(255,255,255,0.8);
    }
    .infobox-content p {
      margin-bottom: 12px;
    }
    .infobox-content b {
      color: #3a4a64;
      font-weight: 600;
    }
  </style>
  
  <script>
    function toggleInfobox() {
      const content = document.querySelector('.infobox-content');
      const icon = document.querySelector('.toggle-icon');
      if (content.style.display === 'none') {
        content.style.display = 'block';
        icon.classList.add('open');
        icon.classList.remove('fa-plus-circle');
        icon.classList.add('fa-times-circle');
      } else {
        content.style.display = 'none';
        icon.classList.remove('open');
        icon.classList.remove('fa-times-circle');
        icon.classList.add('fa-plus-circle');
      }
    }
  </script>
  

  <div class="post">


    <!-- <div style="background-color: #F9F7FB; padding: 15px; border-radius: 8px; max-width: 730px;">
      <p style="color: #402F7C; margin: 0;">
        I will be recruiting.
      </p>
    </div> -->


    <!-- <p style="margin: 5px 0;">The <a href="https://www.nature.com/articles/s42256-023-00626-4" style="color: #0076df;">delta tuning</a> paper gets published on <a href="https://www.nature.com/natmachintell/" style="color: #0076df;">Nature Machine Intelligence</a>, and it is selected as the cover article of the journal's <a href="https://www.nature.com/natmachintell/volumes/5/issues/3" style="color: #0076df;">March issue</a>.</p> -->


    <!-- <div class="news-infobox" style="border: 0px solid #828282; border-radius: 10px; padding: 10px; background-color: #c397ed09; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); max-width: 730px; margin-left: -0px;"> -->
      <br>


    <div class="news-infobox" style="
        border: 0px solid #828282; 
        border-radius: 10px; 
        padding: 11px; 
        padding-top: 10px;
        max-width: 730px; 
        margin-left: -0px;
        transition: box-shadow 0.3s ease, background-color 0.3s ease;
        overflow-y: auto;
        max-height: 250px;
    " 
    onmouseover="this.style.boxShadow='0 7px 26px rgba(58,175,169,0.13)'; this.style.backgroundColor='#fcfefe';"
    onmouseout="this.style.boxShadow='0 2px 8px rgba(58,175,169,0.06)'; this.style.backgroundColor='#f8fafb';">

    <style>
      .news-infobox {
        background: #f8fafb; 
        border-radius: 14px;
        padding: 28px 22px 18px 22px;
        box-shadow: 0 2px 8px rgba(58,175,169,0.06);
        transition: box-shadow 0.3s, background 0.3s;
        max-width: 730px;
        border: 1px solid #dbecec;
      }
      
      .news-infobox:hover {
        box-shadow: 0 7px 26px rgba(58,175,169,0.13);
        background: #f3faf9;
      }
      
      .news-infobox ul {
        padding: 0;
        margin: 0;
        overflow-y: auto;
      }
      
      .news-infobox ul li {
        margin-bottom: 13px;
        padding: 12px 12px 4px 10px;
        border-radius: 7px;
        background: none;
      }
      
      .news-infobox ul li:last-child {
        margin-bottom: 0;
        padding-bottom: 0;
      }
      
      .news-infobox h6 {
        font-size: 15.5px;
        margin: 0 0 4px 0;
        color: #2e3539;      /* ÊØîÊ≠£ÊñáËâ≤Áï•Ê∑±‰ΩÜ‰∏çÂà∫Áúº */
        font-weight: 450;    /* Á®çÂä†Á≤óËÄåÂ∑≤ */
        letter-spacing: 0.01em;
        line-height: 1.4;
      }
            
      .news-infobox span {
        display: block;
        margin-bottom: 4px;
        color: #5b7b88;
        font-size: 0.9em;
      }
      
      .news-infobox p {
        margin: 5px 0 0 0;
        line-height: 1.7;
        color: #294550;
        font-size: 15px;
      }
      

.news-infobox a {
  color: #48656b;
  
  text-underline-offset: 1.5px;
  transition: color 0.18s, background 0.18s;
  border-radius: 4px;
  padding: 0 2px;
  font-weight: 500;
}
.news-infobox a:hover,
.news-infobox a:focus {
  color: #044068;
  background: #ebf7fa;
  text-decoration: underline;
}
      </style>
      <ul style="list-style-type: none; padding: 0;">
        <li style="margin-bottom: 10px;">
          <h6 style="margin: 0;  font-size: 15px;">New Research on self-evolving method and the entropy mechanism of RL</h6>
          <span style="color: #828282; font-size: 0.8em;">May 2025</span>
          <p style="margin: 5px 0;"> Introducing <a href="https://arxiv.org/abs/2504.16084">test time reinforcement learning (TTRL) </a> and the <a href="https://arxiv.org/abs/2505.22617"> Entropy Mechanism </a>, two latest research on self-evolving method and the entropy mechanism of reinforcement learning.
          </p>
        </li>
        <li style="margin-bottom: 10px;">
          <h6 style="margin: 0; ; font-size: 15px;">New Research on Exploration-based Method for Advanced Reasoning Released</h6>
          <span style="color: #828282; font-size: 0.8em;">January 2025</span>
          <p style="margin: 5px 0;"> We recently released <a href="https://arxiv.org/abs/2412.01981" >Implicit Process Reward Modeling (ImplicitPRM)</a> and <a href="https://arxiv.org/abs/2502.01456" >Process Reinforcement through Implicit Rewards (PRIME)</a>, scalable solutions for using (nearly) pure reinforcement learning to advance the reasoning capability of language models. We basically focus on two problems: (1) how to efficiently generate reliable dense rewards and (2) how to effectively use them.
          </p>
        </li>
        <li style="margin-bottom: 10px;">
          <h6 style="margin: 0;  font-size: 15px;">Personal Update</h6> 
          <span style="color: #828282; font-size: 0.8em;">January 2025</span>
          <p style="margin: 5px 0;"> I will be starting as an assistant professor at the EE department of Tsinghua University in 2025.</p>
        </li>
      </ul>
    </div>

<!-- Add a sidebar with content -->



</article>
    
      <div class="publications">
  <h4>Selected Papers</h4>
  <br>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/entropy2.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:entropy" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              
                Ganqu Cui,
              
            
          
        
      
        
        
        
        
          
            
              
                Yuchen Zhang,
              
            
          
        
      
        
        
        
        
          
            
              
                Jiacheng Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Lifan Yuan,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhi Wang,
              
            
          
        
      
        
        
        
        
          
            
              
                Yuxin Zuo,
              
            
          
        
      
        
        
        
        
          
            
              
                Haozhan Li,
              
            
          
        
      
        
        
        
        
          
            
              
                Yuchen Fan,
              
            
          
        
      
        
        
        
        
          
            
              
                Huayu Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Weize Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Hao Peng,
              
            
          
        
      
        
        
        
        
          
            
              
                Lei Bai,
              
            
          
        
      
        
        
        
        
          
            
              
                Wanli Ouyang,
              
            
          
        
      
        
        
        
        
          
            
              
                Yu Cheng,
              
            
          
        
      
        
        
        
        
          
            
              
                Bowen Zhou,
              
            
          
        
      
        
        
        
        
          
            
              and <u><strong>Ning Ding<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" style="vertical-align:-2px;margin-left:2px;fill:#000e19;" viewBox="0 0 24 24"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm0 2v.01L12 13 4 6.01V6h16zM4 8.06l7.49 6.22a1 1 0 0 0 1.02 0L20 8.06V18H4V8.06z"/></svg></strong></u>
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>Preprint</em>
      
      
        
      
      
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2505.22617" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/PRIME-RL/Entropy-Mechanism-of-RL" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper aims to overcome a major obstacle in scaling RL for reasoning with LLMs, namely the collapse of policy entropy. Such phenomenon is consistently observed across vast RL runs without entropy intervention, where the policy entropy dropped sharply at the early training stage, this diminished exploratory ability is always accompanied with the saturation of policy performance. In practice, we establish a transformation equation R=-a*e^H+b between entropy H and downstream performance R. This empirical law strongly indicates that, the policy performance is traded from policy entropy, thus bottlenecked by its exhaustion, and the ceiling is fully predictable H=0, R=-a+b. Our finding necessitates entropy management for continuous exploration toward scaling compute for RL. To this end, we investigate entropy dynamics both theoretically and empirically. Our derivation highlights that, the change in policy entropy is driven by the covariance between action probability and the change in logits, which is proportional to its advantage when using Policy Gradient-like algorithms. Empirical study shows that, the values of covariance term and entropy differences matched exactly, supporting the theoretical conclusion. Moreover, the covariance term stays mostly positive throughout training, further explaining why policy entropy would decrease monotonically. Through understanding the mechanism behind entropy dynamics, we motivate to control entropy by restricting the update of high-covariance tokens. Specifically, we propose two simple yet effective techniques, namely Clip-Cov and KL-Cov, which clip and apply KL penalty to tokens with high covariances respectively. Experiments show that these methods encourage exploration, thus helping policy escape entropy collapse and achieve better downstream performance.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">preprint:entropy</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprint}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{entropy2.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cui, Ganqu and Zhang, Yuchen and Chen, Jiacheng and Yuan, Lifan and Wang, Zhi and Zuo, Yuxin and Li, Haozhan and Fan, Yuchen and Chen, Huayu and Chen, Weize and Liu, Zhiyuan and Peng, Hao and Bai, Lei and Ouyang, Wanli and Cheng, Yu and Zhou, Bowen and Ding, Ning*}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/PRIME-RL/Entropy-Mechanism-of-RL}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2505.22617}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/TTRL.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:ttrl" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         TTRL: Test-time Reinforcement Learning  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              
                Yuxin Zuo,
              
            
          
        
      
        
        
        
        
          
            
              
                Kaiyan Zhang,
              
            
          
        
      
        
        
        
        
          
            
              
                Shang Qu,
              
            
          
        
      
        
        
        
        
          
            
              
                Li Sheng,
              
            
          
        
      
        
        
        
        
          
            
              
                Xuekai Zhu,
              
            
          
        
      
        
        
        
        
          
            
              
                Biqing Qi,
              
            
          
        
      
        
        
        
        
          
            
              
                Youbang Sun,
              
            
          
        
      
        
        
        
        
          
            
              
                Ganqu Cui,
              
            
          
        
      
        
        
        
        
          
            
              <u><strong>Ning Ding<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" style="vertical-align:-2px;margin-left:2px;fill:#000e19;" viewBox="0 0 24 24"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm0 2v.01L12 13 4 6.01V6h16zM4 8.06l7.49 6.22a1 1 0 0 0 1.02 0L20 8.06V18H4V8.06z"/></svg></strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                and Bowen Zhou
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>Preprint</em>
      
      
        
      
      
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2504.16084" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/PRIME-RL/TTRL" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 211% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the maj@n metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model maj@n, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks and highlight TTRL‚Äôs potential for broader tasks and domains.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">preprint:ttrl</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TTRL: Test-time Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{TTRL.png}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zuo, Yuxin and Zhang, Kaiyan and Qu, Shang and Sheng, Li and Zhu, Xuekai and Qi, Biqing and Sun, Youbang and Cui, Ganqu and Ding, Ning* and Zhou, Bowen}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprint}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/PRIME-RL/TTRL}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2504.16084}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/prime.gif"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:prime" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         Process Reinforcement through Implicit Rewards  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              
                Ganqu Cui,
              
            
          
        
      
        
        
        
        
          
            
              
                Lifan Yuan,
              
            
          
        
      
        
        
        
        
          
            
              
                Zefan Wang,
              
            
          
        
      
        
        
        
        
          
            
              
                Hanbin Wang,
              
            
          
        
      
        
        
        
        
          
            
              
                Wendi Li,
              
            
          
        
      
        
        
        
        
          
            
              
                Bingxiang He,
              
            
          
        
      
        
        
        
        
          
            
              
                Yuchen Fan,
              
            
          
        
      
        
        
        
        
          
            
              
                Tianyu Yu,
              
            
          
        
      
        
        
        
        
          
            
              
                Qixin Xu,
              
            
          
        
      
        
        
        
        
          
            
              
                Weize Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Jiarui Yuan,
              
            
          
        
      
        
        
        
        
          
            
              
                Huayu Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Kaiyan Zhang,
              
            
          
        
      
        
        
        
        
          
            
              
                Xingtai Lv,
              
            
          
        
      
        
        
        
        
          
            
              
                Shuo Wang,
              
            
          
        
      
        
        
        
        
          
            
              
                Yuan Yao,
              
            
          
        
      
        
        
        
        
          
            
              
                Xu Han,
              
            
          
        
      
        
        
        
        
          
            
              
                Hao Peng,
              
            
          
        
      
        
        
        
        
          
            
              
                Yu Cheng,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Maosong Sun,
              
            
          
        
      
        
        
        
        
          
            
              
                Bowen Zhou,
              
            
          
        
      
        
        
        
        
          
            
              and <u><strong>Ning Ding<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" style="vertical-align:-2px;margin-left:2px;fill:#000e19;" viewBox="0 0 24 24"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm0 2v.01L12 13 4 6.01V6h16zM4 8.06l7.49 6.22a1 1 0 0 0 1.02 0L20 8.06V18H4V8.06z"/></svg></strong></u>
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>Preprint</em>
      
      
        
      
      
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2502.01456" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/PRIME-RL/PRIME" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://huggingface.co/PRIME-RL" class="btn btn-sm z-depth-0" role="button" target="_blank">Huggingface</a>
  
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Dense process rewards have proven a more effective alternative to the sparse outcome-level rewards in the inference-time scaling of large language models (LLMs), particularly in tasks requiring complex multi-step reasoning. While dense rewards also offer an appealing choice for the reinforcement learning (RL) of LLMs since their fine-grained rewards have the potential to address some inherent issues of outcome rewards, such as training efficiency and credit assignment, this potential remains largely unrealized. This can be primarily attributed to the challenges of training process reward models (PRMs) online, where collecting high-quality process labels is prohibitively expensive, making them particularly vulnerable to reward hacking. To address these challenges, we propose PRIME (Process Reinforcement through IMplicit rEwards), which enables online PRM updates using only policy rollouts and outcome labels through implict process rewards. PRIME combines well with various advantage functions and forgoes the dedicated reward model training phrase that existing approaches require, substantially reducing the development overhead. We demonstrate PRIME‚Äôs effectiveness on competitional math and coding. Starting from Qwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several key reasoning benchmarks over the SFT model. Notably, our resulting model, Eurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning benchmarks with 10% of its training data.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">preprint:prime</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Process Reinforcement through Implicit Rewards}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{prime.gif}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cui, Ganqu and Yuan, Lifan and Wang, Zefan and Wang, Hanbin and Li, Wendi and He, Bingxiang and Fan, Yuchen and Yu, Tianyu and Xu, Qixin and Chen, Weize and Yuan, Jiarui and Chen, Huayu and Zhang, Kaiyan and Lv, Xingtai and Wang, Shuo and Yao, Yuan and Han, Xu and Peng, Hao and Cheng, Yu and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen and Ding, Ning*}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprint}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2502.01456}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin arXiv}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/PRIME-RL/PRIME}</span><span class="p">,</span>
  <span class="na">huggingface</span> <span class="p">=</span> <span class="s">{https://huggingface.co/PRIME-RL}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{Preprint}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/implicitPRM.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:implicitPRM" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         Free Process Rewards without Process Labels  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              
                Lifan Yuan,
              
            
          
        
      
        
        
        
        
          
            
              
                Wendi Li,
              
            
          
        
      
        
        
        
        
          
            
              
                Huayu Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Ganqu Cui,
              
            
          
        
      
        
        
        
        
          
            
              <u><strong>Ning Ding<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" style="vertical-align:-2px;margin-left:2px;fill:#000e19;" viewBox="0 0 24 24"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm0 2v.01L12 13 4 6.01V6h16zM4 8.06l7.49 6.22a1 1 0 0 0 1.02 0L20 8.06V18H4V8.06z"/></svg></strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                Kaiyan Zhang,
              
            
          
        
      
        
        
        
        
          
            
              
                Bowen Zhou,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                and Hao Peng
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>ICML 2025</em>
      
      
        
      
      
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2412.01981" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/lifan-yuan/ImplicitPRM" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    <a href="https://huggingface.co/PRIME-RL" class="btn btn-sm z-depth-0" role="button" target="_blank">Huggingface</a>
  
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Different from its counterpart outcome reward models (ORMs), which evaluate the entire responses, a process reward model (PRM) scores a reasoning trajectory step by step, providing denser and more fine grained rewards. However, training a PRM requires labels annotated at every intermediate step, presenting significant challenges for both manual and automatic data collection. This paper aims to address this challenge. Both theoretically and empirically, we show that an <i>implicit PRM</i> can be obtained at no additional cost, by simply training an ORM on the cheaper response-level labels. The only assumption is to parameterize the outcome reward as the log-likelihood ratios of the policy and reference models, which can be optimized regardless of the specific choice of loss objectives. In experiments, we instantiate our implicit PRMs with various objectives and evaluate their performance on MATH. We show that our implicit PRM outperforms a strong MCTS-based baseline <i>√° la</i> Math-Shepherd using less than 1/38 of the training data. Its performance can be further improved with majority voting. We further find that scaling up instructions and responses benefits our implicit PRM, and the latter brings a larger gain. Particularly, we find that our implicit PRM, when instantiated with the cross-entropy (CE) loss, is more data-efficient and can keep improving generation models even when trained with only one response per instruction, the setup that suffers from extreme data scarcity and imbalance. Further, instructions should be relevant to downstream tasks while the diversity of responses does not bring gains. Surprisingly, training on extra Math-Shepherd step labels brings no further improvements to our implicit PRM trained on only outcome data. We hope that our work will encourage a rethinking of PRM training approaches and contribute to making training PRMs more accessible.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">preprint:implicitPRM</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Free Process Rewards without Process Labels}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{implicitPRM.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yuan, Lifan and Li, Wendi and Chen, Huayu and Cui, Ganqu and Ding, Ning* and Zhang, Kaiyan and Zhou, Bowen and Liu, Zhiyuan and Peng, Hao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ICML 2025}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2412.01981}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin ICML 2025}</span><span class="p">,</span>
  <span class="na">huggingface</span> <span class="p">=</span> <span class="s">{https://huggingface.co/PRIME-RL}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/lifan-yuan/ImplicitPRM}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{Preprint}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/NMI.jpg"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Nat.  <br>Mach. <br>Intell.</abbr>
    
  
  </div> -->

  <div id="2023:delta" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         Parameter-efficient Fine-tuning of Large-scale Pre-trained Language Models  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              <u><strong>Ning Ding</strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                Yujia Qin,
              
            
          
        
      
        
        
        
        
          
            
              
                Guang Yang,
              
            
          
        
      
        
        
        
        
          
            
              
                Fuchao Wei,
              
            
          
        
      
        
        
        
        
          
            
              
                Zonghan Yang,
              
            
          
        
      
        
        
        
        
          
            
              
                Yusheng Su,
              
            
          
        
      
        
        
        
        
          
            
              
                Shengding Hu,
              
            
          
        
      
        
        
        
        
          
            
              
                Yulin Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Chi-Min Chan,
              
            
          
        
      
        
        
        
        
          
            
              
                Weize Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Jing Yi,
              
            
          
        
      
        
        
        
        
          
            
              
                Weilin Zhao,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Hai-Tao Zheng,
              
            
          
        
      
        
        
        
        
          
            
              
                Jianfei Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Yang Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Jie Tang,
              
            
          
        
      
        
        
        
        
          
            
              
                Juanzi Li,
              
            
          
        
      
        
        
        
        
          
            
              
                and Maosong Sun
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>Nature Machine Intelligence</em>
      
      
        
      
      
        <br> <font color="BB0A21">  Cover Article of Nature Machine Intelligence‚Äôs March Issue  </font></strong> <br>   <font color="BB0A21">  World Artificial Intelligence Conference Youth Outstanding Paper Award  </font> 
    
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
      <a href="http://arxiv.org/abs/2203.06904" class="btn btn-sm z-depth-0" role="button" target="_blank">ArXiv</a>
    
    
      <a href="https://www.nature.com/articles/s42256-023-00626-4" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    

    
      
      <a href="https://www.nature.com/articles/s42256-023-00626-4" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/thunlp/OpenDelta" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>As pre-trained language models (PLMs) have become the fundamental infrastructure for various NLP tasks and researchers have readily enjoyed themselves in the pretrainingfinetuning paradigm, evidence from emerging research has continuously proven that larger models tend to yield better performance. However, despite the welcome outcome, the process of fine-tuning large-scale PLMs brings prohibitive adaptation costs. In fact, finetuning all the parameters of a colossal model and retaining separate instances for different tasks are practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs. In order to unleash the imagination of the possible advantages of such methods, not limited to parameter efficiency, we coined a new term delta tuning from a morphological point of view to refer to the original ‚Äúparameter efficient tuning‚Äù. In contrast with the standard fine-tuning, delta tuning only fine-tunes a small portion of the model parameters while keeping the rest untouched, largely reducing both the computation and storage costs. Recent studies have demonstrated that a series of delta tuning methods with distinct tuned parameter selection could achieve performance on a par with full-parameter fine-tuning, suggesting a new promising way of stimulating large-scale PLMs. In this paper, we first formally describe the problem of delta tuning and then comprehensively review recent delta tuning approaches. We also propose a unified categorization criterion that divides existing delta tuning methods into three groups: addition-based, specification-based, and reparameterization-based methods. Though initially proposed as an efficient method to steer large models, we believe that some of the fascinating evidence discovered along with delta tuning could help further reveal the mechanisms of PLMs and even deep neural networks. To this end, we discuss the theoretical principles underlying the effectiveness of delta tuning and propose frameworks to interpret delta tuning from the perspective of optimization and optimal control, respectively. Furthermore, we provide a holistic empirical study of representative methods, where results on over 100 NLP tasks demonstrate a comprehensive performance comparison of different approaches. The experimental results also cover the analysis of combinatorial, scaling and transferable properties of delta tuning. To facilitate the research of delta tuning, we are also developing an open-source toolkit, OpenDelta , that enables practitioners to efficiently and flexibly implement delta tuning on PLMs. At last, we discuss a series of real-world applications of delta tuning.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">2023:delta</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Parameter-efficient Fine-tuning of Large-scale Pre-trained Language Models}</span><span class="p">,</span>
  <span class="na">titleb</span> <span class="p">=</span> <span class="s">{Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{NMI.jpg}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Nat.  &lt;br&gt;Mach. &lt;br&gt;Intell.}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/thunlp/OpenDelta}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and Yi, Jing and Zhao, Weilin and Liu, Zhiyuan and Zheng, Hai-Tao and Chen, Jianfei and Liu, Yang and Tang, Jie and Li, Juanzi and Sun, Maosong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Machine Intelligence}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2203.06904}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://www.nature.com/articles/s42256-023-00626-4}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.nature.com/articles/s42256-023-00626-4}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{  &lt;br&gt; &lt;font color="BB0A21"&gt;  Cover Article of Nature Machine Intelligence's March Issue  &lt;/font&gt;&lt;/strong&gt; &lt;br&gt;   &lt;font color="BB0A21"&gt;  World Artificial Intelligence Conference Youth Outstanding Paper Award  &lt;/font&gt; }</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin Nature Machine Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/op.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="ding2021openprompt" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
          OpenPrompt: An Open-source Framework for Prompt-learning  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              <u><strong>Ning Ding</strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                Shengding Hu,
              
            
          
        
      
        
        
        
        
          
            
              
                Weilin Zhao,
              
            
          
        
      
        
        
        
        
          
            
              
                Yulin Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Hai-Tao Zheng,
              
            
          
        
      
        
        
        
        
          
            
              
                and Maosong Sun
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>ACL System Demonstration</em>
      
      
        
          2022
        
      
      
       <br> <img src="/assets/img/award.png" width="15px">   <font color="BB0A21">  Best Demo Paper Award  </font>
    
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    
      <a href="https://arxiv.org/abs/2111.01998" class="btn btn-sm z-depth-0" role="button" target="_blank">Link</a>
    

    
      
      <a href="https://arxiv.org/pdf/2111.01998.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/thunlp/OpenPrompt" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Prompt-learning has become a new paradigm in modern natural language processing, which directly adapts pre-trained language models (PLMs) to cloze-style prediction, autoregressive modeling, or sequence to sequence generation, resulting in promising performances on various tasks. However, no standard implementation framework of prompt-learning is proposed yet, and most existing prompt-learning codebases, often unregulated, only provide limited implementations for specific scenarios. Since there are many details such as templating strategy, initializing strategy, and verbalizing strategy, etc. need to be considered in prompt-learning, practitioners face impediments to quickly adapting the desired prompt learning methods to their applications. In this paper, we present OpenPrompt, a unified easy-to-use toolkit to conduct prompt-learning over PLMs. OpenPrompt is a research-friendly framework that is equipped with efficiency, modularity, and extendibility, and its combinability allows the freedom to combine different PLMs, task formats, and prompting modules in a unified paradigm. Users could expediently deploy prompt-learning frameworks and evaluate the generalization of them on different NLP tasks without constraints.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ding2021openprompt</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{op.png}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ OpenPrompt: An Open-source Framework for Prompt-learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ding, Ning and Hu, Shengding and Zhao, Weilin and Chen, Yulin and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACL System Demonstration}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin ACL System Demonstration}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2111.01998}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2111.01998.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/thunlp/OpenPrompt}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{ &lt;br&gt; &lt;img src="/assets/img/award.png" width="15px"&gt;   &lt;font color="BB0A21"&gt;  Best Demo Paper Award  &lt;/font&gt;}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/ultra_logo.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:ultra" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         Enhancing Chat Language Models by Scaling High-quality Instructional Conversations  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              <u><strong>Ning Ding</strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                Yulin Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Bokai Xu,
              
            
          
        
      
        
        
        
        
          
            
              
                Yujia Qin,
              
            
          
        
      
        
        
        
        
          
            
              
                Shengding Hu,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Maosong Sun,
              
            
          
        
      
        
        
        
        
          
            
              
                and Bowen Zhou
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>EMNLP</em>
      
      
        
          2023
        
      
      
       <br>   The Ultra series solutions also contain other works like <a href="https://arxiv.org/abs/2310.01377">UltraFeedback (ICML 2024)</a>  </font></strong> , <a href="https://arxiv.org/abs/2404.02078">UltraInteract (ICLR 2024)</a>  </font></strong>  , <a href="https://arxiv.org/abs/2406.03949">UltraMedical (NeurIPS 2024)</a>  </font></strong>, etc.  </strong>
    
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2305.14233" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/thunlp/UltraChat" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fine-tuning on instruction data has been widely validated as an effective practice for implementing chat language models like ChatGPT. Scaling the diversity and quality of such data, although straightforward, stands a great chance of leading to improved performance. This paper aims to improve the upper bound of open-source models further. We first provide a systematically designed, diverse, informative, large-scale dataset of instructional conversations, UltraChat, which does not involve human queries. Our objective is to capture the breadth of interactions that a human might have with an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively. UltraChat contains 1.5 million high-quality multi-turn dialogues and covers a wide range of topics and instructions. Our statistical analysis of UltraChat reveals its superiority in various key metrics, including scale, average length, diversity, coherence, etc., solidifying its position as a leading open-source dataset. Building upon UltraChat, we fine-tune a LLaMA model to create a powerful conversational model, UltraLLaMA. Our evaluations indicate that UltraLLaMA consistently outperforms other open-source models, including Vicuna, the previously recognized state-of-the-art open-source model.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">preprint:ultra</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Chat Language Models by Scaling High-quality Instructional Conversations}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{ultra_logo.png}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{EMNLP}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2305.14233}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/thunlp/UltraChat}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin EMNLP}</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{ &lt;br&gt;   The Ultra series solutions also contain other works like &lt;a href="https://arxiv.org/abs/2310.01377"&gt;UltraFeedback (ICML 2024)&lt;/a&gt;  &lt;/font&gt;&lt;/strong&gt; , &lt;a href="https://arxiv.org/abs/2404.02078"&gt;UltraInteract (ICLR 2024)&lt;/a&gt;  &lt;/font&gt;&lt;/strong&gt;  , &lt;a href="https://arxiv.org/abs/2406.03949"&gt;UltraMedical (NeurIPS 2024)&lt;/a&gt;  &lt;/font&gt;&lt;/strong&gt;, etc.  &lt;/strong&gt;}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 preview"><img class="preview" src="/ningding97/assets/img/publication_preview/sora.png"></div>


<!-- <div class="row">
  <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="preprint:sora" class="col-sm-8">
    
      <div class="title"> 
         <!-- <img src="/assets/img/paper.svg" width="15px">   -->
         Sparse Low-rank Adaptation of Pre-trained Language Models  </div>    
      <div class="author" style="font-size: 15px;">
        
        
        
        
        
          
            
              <u><strong>Ning Ding</strong></u>,
            
          
        
      
        
        
        
        
          
            
              
                Yulin Chen,
              
            
          
        
      
        
        
        
        
          
            
              
                Bokai Xu,
              
            
          
        
      
        
        
        
        
          
            
              
                Yujia Qin,
              
            
          
        
      
        
        
        
        
          
            
              
                Shengding Hu,
              
            
          
        
      
        
        
        
        
          
            
              
                Zhiyuan Liu,
              
            
          
        
      
        
        
        
        
          
            
              
                Maosong Sun,
              
            
          
        
      
        
        
        
        
          
            
              
                and Bowen Zhou
              
            
          
        
      
      </div>

      <div class="periodical" style="font-size: 15px;">
      
        <em>EMNLP</em>
      
      
        
          2023
        
      
      
      </div>
    

    <div class="links">


    
      <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a>
    
    
    

    
      
      <a href="https://arxiv.org/abs/2311.11696" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/TsinghuaC3I/SoRA" class="btn btn-sm z-depth-0" role="button" target="_blank">CODE</a>
    
    
    
    


    
    <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model‚Äôs memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.</p>
    </div>
    

    

    <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">preprint:sora</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sparse Low-rank Adaptation of Pre-trained Language Models}</span><span class="p">,</span>
  <span class="na">preview</span> <span class="p">=</span> <span class="s">{sora.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2311.11696}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{EMNLP}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{\newlin EMNLP}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/TsinghuaC3I/SoRA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
  </div>
</div>
</li></ol>
</div>

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Google Scholar Infobox</title>

<style>
  :root{
    /* Tweak these to match your own palette if desired */
    --text-blue:   #1967d2;   /* Link / text colour            */
    --pill-bg:     #f1f7ff;   /* Very light blue pill background */
    --icon-bg:     #4285f4;   /* Google blue for the icon tile  */
  }

  /* ======  Pill-shaped infobox / button  ====== */
  .infobox{
    display:inline-flex;
    align-items:center;
    gap:14px;                   /* space between icon & text    */
    padding:12px 24px;
    background:var(--pill-bg);
    border-radius:12px;         /* reduced from 9999px to 12px for less rounded corners */
    font:18px/1.4 "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    color:var(--text-blue);
    text-decoration:none;
    height: 40px;              /* increased height for better click area */
    width: 730px;               /* added width to make it longer */

    /* subtle depth */
    box-shadow:0 2px 4px rgba(0,0,0,.06),
               inset 0 1px 0 rgba(255,255,255,.35);
    transition:transform .15s ease, box-shadow .15s ease;
  }
  .infobox:hover{
    transform:translateY(-2px);
    box-shadow:0 4px 8px rgba(0,0,0,.12),
               inset 0 1px 0 rgba(255,255,255,.35);
  }

  .infobox:active{
    transform:translateY(0);
    box-shadow:0 2px 4px rgba(0,0,0,.08),
               inset 0 1px 0 rgba(255,255,255,.35);
  }

  /* ======  Icon tile (square)  ====== */
  .infobox__icon{
    display:flex;
    justify-content:center;
    align-items:center;
    width:44px;
    height:44px;
    min-width:44px;
    background:var(--icon-bg);
    border-radius:12px;
  }

  .infobox__icon svg{
    width:26px;
    height:26px;
    fill:#fff;                  /* white symbol on blue tile */
  }
</style>
</head>

<body>

<!-- Replace the href with your actual Google Scholar profile URL
<a class="infobox" href="https://scholar.google.com/" target="_blank" rel="noopener">
    <i class="fa-brands fa-google"></i>

  View full publication list on&nbsp;Google&nbsp;Scholar
</a> -->

</body>
</html>

    
    
<br>





<h4>Awards</h4>
<ul>
  <li>Yunfan Award of WAIC, 2024.</li>
  <li>Young Elite Scientists Sponsorship Program by CAST, 2023.</li>
  <li>World Artificial Intelligence Conference Youth Outstanding Paper Award, 2023.</li>
  <li>Shuimu Tsinghua Scholar Program, 2023.</li>
  <li>Zhang Keqian Scholar Program, 2023.</li>
  <li>Outstanding Doctoral Dissertation of Tsinghua University, 2023.</li>
  <li>Outstanding Graduate of DCST, Tsinghua University, 2023.</li>
  <li><a href="https://www.2022.aclweb.org/best-demo-paper-award">ACL Best System Demonstration Paper Award</a>, 2022.</li>
  <li><a href="http://scholarship.baidu.com/">Baidu Ph.D Fellowship</a> (10 recipients worldwide), 2021.</li>
  <li>National Scholarship for Ph.D student, 2021.</li>
  <li>National Scholarship for Ph.D student, 2020.</li>
  <li>Tsingfeng Scholarship, Tsinghua University, 2019.</li>
  <li>CACS Scholarship, 2019.</li>
  <li>Excellent Graduate, 2018.</li>
  <li>National Scholarship for undergraduate student, 2018.</li>
  <li>First-class Academic Scholarship, 2017.</li>
  <li>First-class Academic Scholarship, 2016.</li>
</ul>

<h4>Service</h4>
<ul>
  <li>Nature Machine Intelligence</li>
  <li>Neural Networks</li>
  <li>NeurIPS 2020~2024</li>
  <li>ICML 2021~2024</li>
  <li>ACL 2020~2024</li>
  <li>EMNLP 2020~2024</li>
  <li>COLING 2020, 2022</li>
  <li>AAAI 2020~2024</li>
  <li>IJCAI 2020</li>
</ul>


<!-- Hit Counter -->



  
  

<script>
  window.va = window.va || function () { (window.vaq = window.vaq || []).push(arguments); };
</script>
<script defer src="/_vercel/insights/script.js"></script>


<script>
  window.si = window.si || function () { (window.siq = window.siq || []).push(arguments); };
</script>
<script defer src="/_vercel/speed-insights/script.js"></script>


<!-- <iframe width="87%" height="200" style="margin-left: 0px;" src="https://api.maptiler.com/maps/openstreetmap/?key=2V215Qvhk6kDer0iYTH7#16.4/40.00006/116.31593"></iframe> -->


<div align="center">
  <!-- hitwebcounter Code START -->

  <!-- hitwebcounter Code START -->
  <a href="https://www.hitwebcounter.com" target="_blank">
  <img src="https://hitwebcounter.com/counter/counter.php?page=7999605&style=0007&nbdigits=8&type=page&initCount=756" title="Free Counter" Alt="web counter"   border="0" /></a>         
                            
</div>          

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom" style="opacity: 40%;">
  <div class="container mt-0">
    &copy; Copyright 2025 Ning  Ding.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>

    
    
    Last updated: June 30, 2025.
    
  </div>
</footer>




  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="/ningding97/assets/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/ningding97/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/ningding97/assets/js/common.js"></script>


</html>
